{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "URL Crawl Status Lookup\n",
    "=====================\n",
    "\n",
    "Given a URL, this page will look the URL up in crawl-time and access-time indexes and report on the recent status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "// This is necessary to stop the output area folding up\n",
       "IPython.OutputArea.prototype._should_scroll = function(lines) {return false}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "// This is necessary to stop the output area folding up\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {return false}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install altair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "384b568fc38c43728c6714e70eab33d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='https://www.bl.uk/', description='URL:', layout=Layout(width='800px'), placeâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Javascript\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual, Layout, HTML\n",
    "import ipywidgets as widgets\n",
    "import requests\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "from cdx.cdx_helper import cdx_query, CRAWL_CDX\n",
    "\n",
    "# --\n",
    "# See https://github.com/voila-dashboards/voila/pull/218#issuecomment-553654037\n",
    "# \n",
    "# An additional hook can be added to set the default url:\n",
    "# \n",
    "# --\n",
    "\n",
    "default_url = 'https://www.bl.uk/'\n",
    "\n",
    "\n",
    "\n",
    "def query_to_df(query):\n",
    "    data = []\n",
    "    for h in query:\n",
    "        data.append(h.to_dict())\n",
    "    return pd.DataFrame(data,\n",
    "                        columns=['urlkey', 'crawl_date', 'timestamp', 'original', 'mimetype', 'statuscode',\n",
    "                                 'redirecturl', 'robotflags', 'length', 'offset', 'filename', 'digest'])\n",
    "\n",
    "def get_year_profile(url, cdx_service='http://cdx.api.wa.bl.uk/data-heritrix'):\n",
    "    years = {}\n",
    "    for year in np.arange(2002, 2020):\n",
    "        years[year] = 0\n",
    "    for h in cdx_query(url, cdx_service=cdx_service, limit=100000):\n",
    "        year = int(h.timestamp[0:4])\n",
    "        years[year] += 1\n",
    "    return years\n",
    "\n",
    "def chart_events(source, size):\n",
    "    return alt.Chart(source).transform_calculate(\n",
    "            # Add a link to QA Wayback:\n",
    "            url='https://www.webarchive.org.uk/act/wayback/' + alt.datum.timestamp+ '/' + alt.datum.original\n",
    "        ).mark_circle(size=size).encode(\n",
    "            alt.X('crawl_date'),\n",
    "            alt.Y('statuscode'),\n",
    "            color='source',\n",
    "            href='url:N',\n",
    "            tooltip=['urlkey', 'crawl_date', 'timestamp', 'original', 'mimetype', 'statuscode',\n",
    "                     'redirecturl', 'robotflags', 'length', 'offset', 'filename', 'digest', 'url:N']\n",
    "        ).properties(\n",
    "            width=800,\n",
    "            height=200\n",
    "        ).interactive()\n",
    "\n",
    "# ------------------------------------------------\n",
    "\n",
    "def selected_timestamp(change):\n",
    "    timestamp = change['new']\n",
    "    ts_output.clear_output()\n",
    "    with ts_output:\n",
    "        display(timestamp, change)\n",
    "        ts = \"%s-%s-%s+%s%%3A%s\" % (timestamp[0:4],timestamp[4:6],timestamp[6:8],timestamp[8:10],timestamp[10:12])\n",
    "        display(HTML(\"<a href='http://192.168.45.91:90/intranet/logs/?topic=fc&from_date=%s&url_filter=%s*'>Kafka</a>\" % (ts, url_widget.value)))\n",
    "\n",
    "def lookup(url, limit):\n",
    "    wbdf = query_to_df(cdx_query(url, limit=limit))\n",
    "    wbdf['source'] = 'Wayback'\n",
    "    fcdf = query_to_df(cdx_query(url, cdx_service=CRAWL_CDX, limit=limit))\n",
    "    fcdf['source'] = 'Crawler'\n",
    "    # Plot the overview:\n",
    "    display(chart_events(fcdf, 500) + chart_events(wbdf, 200))    \n",
    "\n",
    "    # Add the time-stamp selector:\n",
    "    times = [(None,None)]\n",
    "    for index, row in fcdf.iterrows():\n",
    "        times.append((\"%s (HTTP %s) %s\" % (row['crawl_date'], row['statuscode'], row.get('filename',None)), row['timestamp']))\n",
    "    ts_widget = widgets.Dropdown(\n",
    "        options=times,\n",
    "        description='Timestamp:'\n",
    "    )\n",
    "    ts_widget.observe(selected_timestamp, names='value')\n",
    "    display(ts_widget)\n",
    "    display(ts_output)\n",
    "\n",
    "\n",
    "\n",
    "# Set up the widgets\n",
    "url_widget = widgets.Text(description=\"URL:\", placeholder=default_url, value=default_url,\n",
    "                          layout=Layout(width='800px'))\n",
    "limit_widget = widgets.IntText(description=\"# results\", value=50)\n",
    "\n",
    "ts_output = widgets.Output()\n",
    "\n",
    "# Assemble the interactive bit:\n",
    "widgets.interact_manual.opts['manual_name'] = 'Lookup this URL'\n",
    "out = interact_manual(lookup, \n",
    "                      url=url_widget,\n",
    "                      limit=limit_widget\n",
    ")\n",
    "\n",
    "# Auto run with the default values so you get the idea:\n",
    "#lookup(url_widget.value, limit_widget.value, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the crawl-time index only holds relatively recent events, whereas the access-time index should hold all events except the most recent."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
